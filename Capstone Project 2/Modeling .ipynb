{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "elect-ribbon",
   "metadata": {},
   "source": [
    "# Modeling: Loan Application Approval\n",
    "### Comparison of Classification Algorithms Performance Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "norman-valley",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/Reeves1/opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - imbalanced-learn\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    conda-4.10.1               |   py38h50d1736_0         3.1 MB  conda-forge\n",
      "    imbalanced-learn-0.8.0     |     pyhd8ed1ab_0         109 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         3.2 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  imbalanced-learn   conda-forge/noarch::imbalanced-learn-0.8.0-pyhd8ed1ab_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda                               4.10.0-py38h50d1736_1 --> 4.10.1-py38h50d1736_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "conda-4.10.1         | 3.1 MB    | ##################################### | 100% \n",
      "imbalanced-learn-0.8 | 109 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-breath",
   "metadata": {},
   "source": [
    "#### In this notebook I will recreate my baseline model, utilizing a 70/30 train-test split, and attempt to boost the recall score of the minority class via oversampling and undersampling as a method of accounting for the imbalanced classes. I will also utilize a Random Forest, and Decision Tree algorithm to compare performance metrics for each on the training data once it has been oversampled and undersampled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acquired-fairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "brown-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.read_csv('data/loan_data_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "complex-theta",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_clean['ApplicantIncome']\n",
    "del df_clean['Loan_ID']\n",
    "del df_clean['CoapplicantIncome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "split-handy",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df = df_clean[['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History', 'Property_Area', 'HouseholdIncome']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "automotive-appointment",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(dummy_df)\n",
    "y = df_clean['Loan_Status'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sublime-feature",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "speaking-reform",
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "#fit the model on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "#introduce variable to be reused later \n",
    "y_predict_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "thorough-abortion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training Classification Report]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.88      0.43      0.58       134\n",
      "           Y       0.79      0.97      0.87       295\n",
      "\n",
      "    accuracy                           0.80       429\n",
      "   macro avg       0.83      0.70      0.73       429\n",
      "weighted avg       0.82      0.80      0.78       429\n",
      "\n",
      "[Test Classification Report]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.40      0.57        58\n",
      "           Y       0.78      1.00      0.88       127\n",
      "\n",
      "    accuracy                           0.81       185\n",
      "   macro avg       0.89      0.70      0.72       185\n",
      "weighted avg       0.85      0.81      0.78       185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predict_training = clf.predict(X_train)\n",
    "print(\"[Training Classification Report]\")\n",
    "print(classification_report(y_train, y_predict_training))\n",
    "\n",
    "print(\"[Test Classification Report]\")\n",
    "print(classification_report(y_test, y_predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-disabled",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "#### Oversampling the minority class will be the first step in attempting to improve the recall of the baseline model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "chemical-newport",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler()\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "israeli-house",
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "#fit the model on the training data\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "#introduce variable to be reused later \n",
    "y_predict_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "initial-worker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training Classification Report]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.50      0.74      0.60       295\n",
      "           Y       0.51      0.27      0.35       295\n",
      "\n",
      "    accuracy                           0.50       590\n",
      "   macro avg       0.50      0.50      0.48       590\n",
      "weighted avg       0.50      0.50      0.48       590\n",
      "\n",
      "[Test Classification Report]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.27      0.55      0.36        58\n",
      "           Y       0.60      0.31      0.41       127\n",
      "\n",
      "    accuracy                           0.38       185\n",
      "   macro avg       0.43      0.43      0.38       185\n",
      "weighted avg       0.50      0.38      0.39       185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predict_training = clf.predict(X_resampled)\n",
    "print(\"[Training Classification Report]\")\n",
    "print(classification_report(y_resampled, y_predict_training))\n",
    "\n",
    "print(\"[Test Classification Report]\")\n",
    "print(classification_report(y_test, y_predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-ethernet",
   "metadata": {},
   "source": [
    "#### The performance metrics for the baseline model after being oversampled for the minority class performs better in the training Classification report for recall increasing from .43 to .74. We see an increase in recall in the Test set as well, however, in both models the Precision score of the Majority Class is significantly worse. I am curious to see how SMOTE affects the recall score of this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "military-fifteen",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "residential-study",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training Classification Report]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.93      0.76      0.83       295\n",
      "           Y       0.79      0.94      0.86       295\n",
      "\n",
      "    accuracy                           0.85       590\n",
      "   macro avg       0.86      0.85      0.85       590\n",
      "weighted avg       0.86      0.85      0.85       590\n",
      "\n",
      "[Test Classification Report]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.76      0.43      0.55        58\n",
      "           Y       0.78      0.94      0.85       127\n",
      "\n",
      "    accuracy                           0.78       185\n",
      "   macro avg       0.77      0.68      0.70       185\n",
      "weighted avg       0.77      0.78      0.76       185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_resampled1, y_resampled1 = SMOTE().fit_resample(X_train, y_train)\n",
    "#construct Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "#fit the model on the training data\n",
    "clf.fit(X_resampled1, y_resampled1)\n",
    "#introduce variable to be reused later \n",
    "y_predict_test = clf.predict(X_test)\n",
    "y_predict_training = clf.predict(X_resampled1)\n",
    "print(\"[Training Classification Report]\")\n",
    "print(classification_report(y_resampled1, y_predict_training))\n",
    "\n",
    "print(\"[Test Classification Report]\")\n",
    "print(classification_report(y_test, y_predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-assurance",
   "metadata": {},
   "source": [
    "#### SMOTE provided interesting results! The recall metric in the Training set was significantly higher than the baseline model and the Precision score did not suffer any decline remaining at .79. Precision score for the minority class and recall for the majority class were decreased by .07 and .06 respectively. Performance on the test set was significantly worse than the training set, with the recall for the minority class seeing no improvement. Undersampling will be the final method I attempt on this baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "intensive-delhi",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler()\n",
    "X_resampled2, y_resampled2 = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "reduced-insulin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training Classification Report]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.74      0.67      0.71       134\n",
      "           Y       0.70      0.77      0.73       134\n",
      "\n",
      "    accuracy                           0.72       268\n",
      "   macro avg       0.72      0.72      0.72       268\n",
      "weighted avg       0.72      0.72      0.72       268\n",
      "\n",
      "[Test Classification Report]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.49      0.60      0.54        58\n",
      "           Y       0.80      0.71      0.75       127\n",
      "\n",
      "    accuracy                           0.68       185\n",
      "   macro avg       0.64      0.66      0.64       185\n",
      "weighted avg       0.70      0.68      0.68       185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#construct Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "#fit the model on the training data\n",
    "clf.fit(X_resampled2, y_resampled2)\n",
    "#introduce variable to be reused later \n",
    "y_predict_test = clf.predict(X_test)\n",
    "y_predict_training = clf.predict(X_resampled2)\n",
    "print(\"[Training Classification Report]\")\n",
    "print(classification_report(y_resampled2, y_predict_training))\n",
    "\n",
    "print(\"[Test Classification Report]\")\n",
    "print(classification_report(y_test, y_predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-connection",
   "metadata": {},
   "source": [
    "#### Performance metrics for the minority class recall has seen the best improvement in the test set with an increase from .43 to .60, while simultaneously improving the precision of the majority class in the test set. There was a significant decrease in performance of the precision for the minority class in the test set that cannot be ignored, however. At this point, I have achieved the goal of improving the recall score of the minority class by utilizing undersampling of the training set. Utilizing both oversampling and undersampling, as well as SMOTE on a Random Forest Algorithm will be my next step. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "native-methodology",
   "metadata": {},
   "source": [
    "## Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "statewide-anniversary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training Classification Report]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      1.00      1.00       295\n",
      "           Y       1.00      1.00      1.00       295\n",
      "\n",
      "    accuracy                           1.00       590\n",
      "   macro avg       1.00      1.00      1.00       590\n",
      "weighted avg       1.00      1.00      1.00       590\n",
      "\n",
      "[Test Classification Report]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.69      0.57      0.62        58\n",
      "           Y       0.82      0.88      0.85       127\n",
      "\n",
      "    accuracy                           0.78       185\n",
      "   macro avg       0.75      0.73      0.74       185\n",
      "weighted avg       0.78      0.78      0.78       185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "ros = RandomOverSampler()\n",
    "X_resampled3, y_resampled3 = ros.fit_resample(X_train, y_train)\n",
    "clf.fit(X_resampled3, y_resampled3)\n",
    "y_predict_test = clf.predict(X_test)\n",
    "y_predict_training = clf.predict(X_resampled3)\n",
    "print(\"[Training Classification Report]\")\n",
    "print(classification_report(y_resampled3, y_predict_training))\n",
    "\n",
    "print(\"[Test Classification Report]\")\n",
    "print(classification_report(y_test, y_predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handmade-palestine",
   "metadata": {},
   "source": [
    "#### The training set results were perfect across the board for the Random Forest model, with the test set being significantly better than the oversampling results on the baseline Log. Regression model. It will be interesting to see the effects of SMOTE on this model as well! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "secondary-saudi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training Classification Report]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      1.00      1.00       295\n",
      "           Y       1.00      1.00      1.00       295\n",
      "\n",
      "    accuracy                           1.00       590\n",
      "   macro avg       1.00      1.00      1.00       590\n",
      "weighted avg       1.00      1.00      1.00       590\n",
      "\n",
      "[Test Classification Report]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.71      0.55      0.62        58\n",
      "           Y       0.81      0.90      0.85       127\n",
      "\n",
      "    accuracy                           0.79       185\n",
      "   macro avg       0.76      0.72      0.74       185\n",
      "weighted avg       0.78      0.79      0.78       185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_resampled4, y_resampled4 = SMOTE().fit_resample(X_train, y_train)\n",
    "#construct Logistic Regression model\n",
    "clf = RandomForestClassifier()\n",
    "#fit the model on the training data\n",
    "clf.fit(X_resampled4, y_resampled4)\n",
    "#introduce variable to be reused later \n",
    "y_predict_test = clf.predict(X_test)\n",
    "y_predict_training = clf.predict(X_resampled4)\n",
    "print(\"[Training Classification Report]\")\n",
    "print(classification_report(y_resampled4, y_predict_training))\n",
    "\n",
    "print(\"[Test Classification Report]\")\n",
    "print(classification_report(y_test, y_predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-bouquet",
   "metadata": {},
   "source": [
    "#### Overall, this model performs marginally better on the test set than Random Oversampled model with the Precision scores of both classes increasing as well as the recall score of the Majority class. The recall for the minority class performed a little worse, by .02, in this model than the ROS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "asian-cooking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training Classification Report]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      1.00      1.00       134\n",
      "           Y       1.00      1.00      1.00       134\n",
      "\n",
      "    accuracy                           1.00       268\n",
      "   macro avg       1.00      1.00      1.00       268\n",
      "weighted avg       1.00      1.00      1.00       268\n",
      "\n",
      "[Test Classification Report]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.52      0.60      0.56        58\n",
      "           Y       0.81      0.75      0.78       127\n",
      "\n",
      "    accuracy                           0.70       185\n",
      "   macro avg       0.66      0.68      0.67       185\n",
      "weighted avg       0.72      0.70      0.71       185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rus = RandomUnderSampler()\n",
    "X_resampled5, y_resampled5 = rus.fit_resample(X_train, y_train)\n",
    "#construct Logistic Regression model\n",
    "clf = RandomForestClassifier()\n",
    "#fit the model on the training data\n",
    "clf.fit(X_resampled5, y_resampled5)\n",
    "#introduce variable to be reused later \n",
    "y_predict_test = clf.predict(X_test)\n",
    "y_predict_training = clf.predict(X_resampled5)\n",
    "print(\"[Training Classification Report]\")\n",
    "print(classification_report(y_resampled5, y_predict_training))\n",
    "\n",
    "print(\"[Test Classification Report]\")\n",
    "print(classification_report(y_test, y_predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-fifth",
   "metadata": {},
   "source": [
    "#### Comparing the recall and precision scores for the ROS, RUS, and SMOTE resampling for the Random Forest Model, I believe the best model would be the SMOTE resampled Random Forest. This model performs better than the baseline model as well! Looking at how another algorithm performs will be valuable as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-canal",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "prompt-armor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aerial-blond",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training Classification Report]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      1.00      1.00       295\n",
      "           Y       1.00      1.00      1.00       295\n",
      "\n",
      "    accuracy                           1.00       590\n",
      "   macro avg       1.00      1.00      1.00       590\n",
      "weighted avg       1.00      1.00      1.00       590\n",
      "\n",
      "[Test Classification Report]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.49      0.43      0.46        58\n",
      "           Y       0.75      0.80      0.77       127\n",
      "\n",
      "    accuracy                           0.68       185\n",
      "   macro avg       0.62      0.61      0.62       185\n",
      "weighted avg       0.67      0.68      0.68       185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "ros = RandomOverSampler()\n",
    "X_resampled6, y_resampled6 = ros.fit_resample(X_train, y_train)\n",
    "clf.fit(X_resampled6, y_resampled6)\n",
    "y_predict_test = clf.predict(X_test)\n",
    "y_predict_training = clf.predict(X_resampled6)\n",
    "print(\"[Training Classification Report]\")\n",
    "print(classification_report(y_resampled6, y_predict_training))\n",
    "\n",
    "print(\"[Test Classification Report]\")\n",
    "print(classification_report(y_test, y_predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-writer",
   "metadata": {},
   "source": [
    "#### It appears as though the Decision Tree Classifier performance after ROS is closer to the results we saw from the Log. Reg. Model, that being it is not quite as good as the Random Forest Model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "otherwise-literature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training Classification Report]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      1.00      1.00       295\n",
      "           Y       1.00      1.00      1.00       295\n",
      "\n",
      "    accuracy                           1.00       590\n",
      "   macro avg       1.00      1.00      1.00       590\n",
      "weighted avg       1.00      1.00      1.00       590\n",
      "\n",
      "[Test Classification Report]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.50      0.50      0.50        58\n",
      "           Y       0.77      0.77      0.77       127\n",
      "\n",
      "    accuracy                           0.69       185\n",
      "   macro avg       0.64      0.64      0.64       185\n",
      "weighted avg       0.69      0.69      0.69       185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_resampled7, y_resampled7 = SMOTE().fit_resample(X_train, y_train)\n",
    "#construct Logistic Regression model\n",
    "clf = DecisionTreeClassifier()\n",
    "#fit the model on the training data\n",
    "clf.fit(X_resampled7, y_resampled7)\n",
    "#introduce variable to be reused later \n",
    "y_predict_test = clf.predict(X_test)\n",
    "y_predict_training = clf.predict(X_resampled7)\n",
    "print(\"[Training Classification Report]\")\n",
    "print(classification_report(y_resampled7, y_predict_training))\n",
    "\n",
    "print(\"[Test Classification Report]\")\n",
    "print(classification_report(y_test, y_predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "synthetic-possible",
   "metadata": {},
   "source": [
    "#### We see a similar performance in this model with SMOTE resampling methods applied, marginally better than the baseline model, but not as good as the Random Forest Model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "traditional-triangle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training Classification Report]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      1.00      1.00       134\n",
      "           Y       1.00      1.00      1.00       134\n",
      "\n",
      "    accuracy                           1.00       268\n",
      "   macro avg       1.00      1.00      1.00       268\n",
      "weighted avg       1.00      1.00      1.00       268\n",
      "\n",
      "[Test Classification Report]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.41      0.66      0.50        58\n",
      "           Y       0.78      0.57      0.66       127\n",
      "\n",
      "    accuracy                           0.59       185\n",
      "   macro avg       0.60      0.61      0.58       185\n",
      "weighted avg       0.67      0.59      0.61       185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rus = RandomUnderSampler()\n",
    "X_resampled8, y_resampled8 = rus.fit_resample(X_train, y_train)\n",
    "#construct Logistic Regression model\n",
    "clf = DecisionTreeClassifier()\n",
    "#fit the model on the training data\n",
    "clf.fit(X_resampled8, y_resampled8)\n",
    "#introduce variable to be reused later \n",
    "y_predict_test = clf.predict(X_test)\n",
    "y_predict_training = clf.predict(X_resampled8)\n",
    "print(\"[Training Classification Report]\")\n",
    "print(classification_report(y_resampled8, y_predict_training))\n",
    "\n",
    "print(\"[Test Classification Report]\")\n",
    "print(classification_report(y_test, y_predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-affiliation",
   "metadata": {},
   "source": [
    "#### And with the RUS methods on the Decision Tree algorithm we see again that it is not nearly as effective as the Random Forest Model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-duration",
   "metadata": {},
   "source": [
    "#### In conclusion, the Random Forest model utilizing SMOTE as a means of resampling the training data sees the best improvement of the recall score on the test set, with the other performance metrics increasing as well. While it is the BEST model of the ones available, it's recall score is still "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
